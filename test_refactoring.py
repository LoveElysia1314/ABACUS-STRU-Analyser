#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é‡æ„ååŠŸèƒ½éªŒè¯æµ‹è¯•è„šæœ¬
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import numpy as np
from src.utils import ValidationUtils
from src.core.metrics import MetricCalculator
from src.core.sampler import SamplingStrategy, PowerMeanSampler, GreedyMaxDistanceSampler

def test_validation_utils():
    """æµ‹è¯•ç»Ÿä¸€çš„ç©ºæ£€æŸ¥å‡½æ•°"""
    print("Testing ValidationUtils.is_empty()...")
    
    # æµ‹è¯• None
    assert ValidationUtils.is_empty(None) == True
    
    # æµ‹è¯•ç©ºåˆ—è¡¨
    assert ValidationUtils.is_empty([]) == True
    assert ValidationUtils.is_empty([1, 2, 3]) == False
    
    # æµ‹è¯•ç©º numpy æ•°ç»„
    assert ValidationUtils.is_empty(np.array([])) == True
    assert ValidationUtils.is_empty(np.array([1, 2, 3])) == False
    
    # æµ‹è¯•äºŒç»´ç©ºæ•°ç»„
    assert ValidationUtils.is_empty(np.array([]).reshape(0, 2)) == True
    assert ValidationUtils.is_empty(np.array([[1, 2], [3, 4]])) == False
    
    print("âœ“ ValidationUtils.is_empty() tests passed")

def test_metric_calculator():
    """æµ‹è¯• MetricCalculator çš„æ–°å¢å‡½æ•°"""
    print("Testing MetricCalculator extensions...")
    
    # æµ‹è¯•ç©ºè¾“å…¥
    empty_result = MetricCalculator.estimate_mean_distance(np.array([]))
    assert empty_result == 0.0
    
    empty_result = MetricCalculator.calculate_dRMSF(np.array([]))
    assert empty_result == 0.0
    
    empty_result = MetricCalculator.calculate_MeanCV(np.array([]))
    assert empty_result == 0.0
    
    # æµ‹è¯•æ­£å¸¸è¾“å…¥
    test_vectors = np.random.rand(5, 3)
    
    mean_dist = MetricCalculator.estimate_mean_distance(test_vectors)
    assert isinstance(mean_dist, float) and mean_dist >= 0
    
    dRMSF = MetricCalculator.calculate_dRMSF(test_vectors)
    assert isinstance(dRMSF, float) and dRMSF >= 0
    
    meanCV = MetricCalculator.calculate_MeanCV(test_vectors)
    assert isinstance(meanCV, float) and meanCV >= 0
    
    print("âœ“ MetricCalculator extension tests passed")

def test_sampling_strategies():
    """æµ‹è¯•é‡‡æ ·å™¨ç»Ÿä¸€æ¥å£"""
    print("Testing sampling strategies...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_points = np.random.rand(10, 5)
    k = 5
    
    # æµ‹è¯• PowerMeanSampler
    power_sampler = SamplingStrategy.create_sampler(SamplingStrategy.POWER_MEAN)
    selected, swaps, ratio = power_sampler.select_frames(test_points, k)
    assert len(selected) == k
    assert all(0 <= idx < 10 for idx in selected)
    
    # æµ‹è¯• GreedyMaxDistanceSampler
    greedy_sampler = SamplingStrategy.create_sampler(SamplingStrategy.GREEDY_MAX_DISTANCE)
    selected, swaps, ratio = greedy_sampler.select_frames(test_points, k)
    assert len(selected) == k
    assert all(0 <= idx < 10 for idx in selected)
    
    # æµ‹è¯•è¾¹ç•Œæ¡ä»¶
    selected, _, _ = power_sampler.select_frames(test_points, 15)  # k > n
    assert len(selected) == 10  # åº”è¯¥è¿”å›æ‰€æœ‰ç‚¹
    
    print("âœ“ Sampling strategy tests passed")

def test_compute_all_metrics_with_is_empty():
    """æµ‹è¯• compute_all_metrics ä½¿ç”¨æ–°çš„ is_empty æ£€æŸ¥"""
    print("Testing compute_all_metrics with is_empty...")
    
    # æµ‹è¯•ç©ºçŸ©é˜µ
    empty_metrics = MetricCalculator.compute_all_metrics(np.array([]))
    expected_keys = {'global_mean', 'MinD', 'ANND', 'MPD'}
    assert set(empty_metrics.keys()) == expected_keys
    assert empty_metrics['global_mean'] == 0.0
    
    # æµ‹è¯•æ­£å¸¸çŸ©é˜µ
    test_matrix = np.random.rand(8, 10)
    metrics = MetricCalculator.compute_all_metrics(test_matrix)
    assert set(metrics.keys()) == expected_keys
    assert metrics['global_mean'] > 0
    
    print("âœ“ compute_all_metrics with is_empty tests passed")

if __name__ == "__main__":
    print("Running refactoring validation tests...\n")
    
    test_validation_utils()
    test_metric_calculator()
    test_sampling_strategies()
    test_compute_all_metrics_with_is_empty()
    
    print("\nğŸ‰ All refactoring tests passed! The refactored code is working correctly.")
